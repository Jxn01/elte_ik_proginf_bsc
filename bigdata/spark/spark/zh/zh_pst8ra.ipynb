{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark ZH\n",
    "## NEPTUN: PST8RA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/09 08:27:38 WARN Utils: Your hostname, jxn-linux resolves to a loopback address: 127.0.1.1; using 10.10.116.13 instead (on interface wlp4s0)\n",
      "23/11/09 08:27:38 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/09 08:27:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/11/09 08:27:39 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/09 08:27:54 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext \n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "conf = SparkConf().set(\"spark.local.dir\", \"/home/jxn/.sparktmp\") # A local dir nélkül nem működik a configom, de azt ki lehet majd törölni\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/09 09:22:39 WARN Utils: Your hostname, jxn-linux resolves to a loopback address: 127.0.1.1; using 10.10.116.13 instead (on interface wlp4s0)\n",
      "23/11/09 09:22:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/09 09:22:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. FELADAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'GCT': 136, 'CTT': 78, 'TTT': 126, 'TTC': 103, 'TCA': 111, 'CAT': 95, 'ATT': 114, 'TCT': 95, 'CTG': 176, 'TGA': 151, 'ACT': 70, 'TGC': 166, 'AAT': 124, 'ATA': 71, 'TAT': 80, 'ATG': 132, 'TGT': 75, 'GTC': 71, 'CTC': 77, 'GTG': 112, 'TGG': 151, 'GAT': 142, 'TTA': 95, 'TAA': 80, 'AGT': 72, 'TAG': 37, 'GGT': 113, 'GTT': 125, 'TAC': 67, 'CCT': 62, 'CGT': 106, 'GTA': 59, 'TTG': 121, 'CTA': 33, 'ATC': 126, 'TCC': 71, 'TCG': 95})\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "def k_mer(line):\n",
    "  kmers = []\n",
    "  i = 0\n",
    "  while(i+2 < len(line)):\n",
    "    kmers.append(line[i:i+3])\n",
    "    i+=1\n",
    "  return kmers\n",
    "\n",
    "kmer_dict = sc.textFile('kmerInput.txt')\\\n",
    "  .map(lambda line : k_mer(line))\\\n",
    "  .flatMap(lambda x : x)\\\n",
    "  .filter(lambda kmer : \"T\" in kmer)\\\n",
    "  .countByValue()\n",
    "\n",
    "result = sc.parallelize(kmer_dict.values()).filter(lambda value: value > 100).count()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. FELADAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('elte.hu', 3, 53)\n"
     ]
    }
   ],
   "source": [
    "weboldalak = sc.textFile('weboldalak.txt')\\\n",
    "  .map(lambda line: (line.split(\" \", 1)[0], line.split(\" \", 1)[1]))\\\n",
    "  .filter(lambda web: len(web[1]) > 10)\\\n",
    "  .map(lambda web: (web[0], len(list(filter(lambda x: x == \"ELTE\" or x == \"elte\", web[1].split(\" \")))), len(web[1].split(\" \"))))\\\n",
    "  .sortBy(lambda web: web[1], False).take(1)\n",
    "\n",
    "weboldal = weboldalak[0]\n",
    "\n",
    "print(weboldal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. FELADAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|              AUTHOR|count(TITLE)|\n",
      "+--------------------+------------+\n",
      "|       Lewis Carroll|          15|\n",
      "|Petra Mettke, Kar...|          11|\n",
      "|    L. M. Montgomery|          11|\n",
      "+--------------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_books = spark.read\\\n",
    "  .format(\"csv\")\\\n",
    "  .option('header', True)\\\n",
    "  .option(\"inferschema\", True)\\\n",
    "  .load(\"books.csv\")\n",
    "  \n",
    "df_books.createOrReplaceTempView(\"BOOKS\")\n",
    "  \n",
    "spark.sql(\"SELECT AUTHOR, COUNT(TITLE) FROM BOOKS WHERE AUTHOR IS NOT NULL GROUP BY AUTHOR, TITLE SORT BY COUNT(TITLE) DESC\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. FELADAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|              AUTHOR|count(PUBLISHER)|\n",
      "+--------------------+----------------+\n",
      "|Shelley Admont, K...|              89|\n",
      "|       Carolyn Keene|              50|\n",
      "|          Adam Blade|              45|\n",
      "|    Roger Hargreaves|              56|\n",
      "|       Die Blokehead|              49|\n",
      "|         R. L. Stine|              78|\n",
      "|     Kirsteen Robson|              39|\n",
      "|       Mohammed Umar|              44|\n",
      "|         Idries Shah|             160|\n",
      "|Steve Barlow, Ste...|              43|\n",
      "|          J. R. Ward|              48|\n",
      "|         Enid Blyton|             127|\n",
      "|          Tuula Pere|              52|\n",
      "|        El Blokehead|              89|\n",
      "|          Tuula Pere|              40|\n",
      "|       James Manning|             105|\n",
      "|         Jake Maddox|              51|\n",
      "|     Peter Hertzberg|              41|\n",
      "|         Thithiajobs|              62|\n",
      "|       Daisy Meadows|              56|\n",
      "|       Penelope Dyan|              79|\n",
      "|       Grace Goodwin|              55|\n",
      "|        Carole Marsh|              67|\n",
      "|         Jules Verne|              88|\n",
      "|Speedy Publishing...|             100|\n",
      "|     Coloring Bandit|              40|\n",
      "|                Anna|              50|\n",
      "|       James Manning|              56|\n",
      "|Shelley Admont, K...|             102|\n",
      "|          Dan Gutman|              45|\n",
      "|    Roger Hargreaves|              36|\n",
      "|  Michelle M. Pillow|              80|\n",
      "|         Erin Hunter|              60|\n",
      "|    Wilfried A. Hary|              46|\n",
      "|          Fiona Watt|              78|\n",
      "|     Garcia Santiago|            1463|\n",
      "|              Panini|              55|\n",
      "|         Erin Hunter|              37|\n",
      "|       Alfred Bekker|              80|\n",
      "|   Jacqueline Wilson|              52|\n",
      "|        Steve Herman|              80|\n",
      "|     Matilde Correia|              53|\n",
      "+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_books = spark.read\\\n",
    "  .format(\"csv\")\\\n",
    "  .option('header', True)\\\n",
    "  .option(\"inferschema\", True)\\\n",
    "  .load(\"books.csv\")\n",
    "  \n",
    "df_books.createOrReplaceTempView(\"BOOKS\")\n",
    "\n",
    "spark.sql(\"SELECT AUTHOR, COUNT(PUBLISHER) FROM BOOKS WHERE AUTHOR IS NOT NULL GROUP BY AUTHOR, PUBLISHER HAVING COUNT(PUBLISHER) > 35\").show(300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
